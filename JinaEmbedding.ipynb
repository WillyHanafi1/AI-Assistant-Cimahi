{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1884d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully!\n",
      "JINA_API_KEY loaded: ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment variables loaded successfully!\")\n",
    "print(f\"JINA_API_KEY loaded: {'✅' if os.getenv('JINA_API_KEY') else '❌'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import json\n",
    "\n",
    "def extract_text_from_pdfs(input_folder, output_file):\n",
    "    \"\"\"Extract text from PDF files in the specified folder and save to a JSON file.\"\"\"\n",
    "    extracted_data = []\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.pdf'):\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            with pdfplumber.open(filepath) as pdf:\n",
    "                text = ''.join([page.extract_text() for page in pdf.pages])\n",
    "                extracted_data.append({\"filename\": filename, \"text\": text})\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(extracted_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "extract_text_from_pdfs('./docs', 'extracted2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def split_text_by_length(text, max_length):\n",
    "    \"\"\"Split text into chunks with a maximum length.\"\"\"\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "def chunk_documents(input_file, output_file, api_url, api_key):\n",
    "    \"\"\"Chunk documents using the Jina Segment API and save the results to a JSON file.\"\"\"\n",
    "    # Load documents from input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "\n",
    "    chunked_data = []\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}'\n",
    "    }\n",
    "    max_api_length = 64000  # 64k chars, a bit less for safety\n",
    "\n",
    "    for doc in documents:\n",
    "        if not doc.get(\"text\"):\n",
    "            print(f\"Skipping document {doc.get('filename', 'unknown')} due to missing or empty text.\")\n",
    "            continue\n",
    "\n",
    "        text_chunks = split_text_by_length(doc[\"text\"], max_api_length)\n",
    "        for part_idx, text_part in enumerate(text_chunks):\n",
    "            data = {\n",
    "                \"content\": text_part,\n",
    "                \"tokenizer\": \"o200k_base\",\n",
    "                \"return_tokens\": True,\n",
    "                \"return_chunks\": True,\n",
    "                \"max_chunk_length\": 1000\n",
    "            }\n",
    "            response = requests.post(api_url, headers=headers, json=data)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"Successfully processed {doc.get('filename', 'unknown')} part {part_idx+1}/{len(text_chunks)}\")\n",
    "                chunks = response.json().get(\"chunks\", [])\n",
    "                for idx, chunk in enumerate(chunks):\n",
    "                    chunked_data.append({\n",
    "                        \"filename\": doc[\"filename\"],\n",
    "                        \"doc_part\": part_idx,\n",
    "                        \"chunk_index\": idx,\n",
    "                        \"chunk\": chunk\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"Error processing {doc.get('filename', 'unknown')} part {part_idx+1}: {response.status_code} {response.text}\")\n",
    "\n",
    "    # Save chunked data to output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunked_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "chunk_documents(\n",
    "    input_file='extracted.json',\n",
    "    output_file='chunks.json',\n",
    "    api_url='https://api.jina.ai/v1/segment',\n",
    "    api_key=os.getenv('JINA_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5b7738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 872\n",
      "\n",
      "Top 10 longest chunks:\n",
      "\n",
      "Chunk #1 (filename: Perwal Cimahi 6 2024.pdf, part: 0, index: 4, length: 997):\n",
      "\n",
      "Badan adalah sekumpulan orang dan/atau modal yang merupakan kesatuan, baik yang melakukan usaha maupun yang tidak melakukan usaha yang meliputi perseroan terbatas, perseroan komanditer, perseroan lainnya, badan usaha milik negara, badan usaha milik daerah, atau badan usaha milik desa, dengan nama dan dalam bentuk apa pun, firma, kongsi, koperasi, dana pensiun, persekutuan, perkumpulan, yayasan, organisasi masa, organisasi sosial politik, atau organisasi lainnya, lembaga dan bentuk badan lainnya,...\n",
      "\n",
      "Chunk #2 (filename: Perwal Cimahi 6 2024.pdf, part: 1, index: 120, length: 986):\n",
      "\n",
      "n Pajak / Reklame Tahun (Rp/M) Pajak BILLBOARD 1 250,000 375,000 500,000 M2 50,000 1 Tahun / BANDO /3 Bln PAPAN MERK 2 (PMT) 100,000 150,000 200,000 M2 50,000 1 Tahun / MELEKAT/ /3 Bln DINDING DAN BANGUNAN NEON SIGN 3 M2 50,000 1 Tahun / NEON 150,000 200,000 250,000 /3 Bln BOX 4 BALIHO 50,000 75,000 75,000 M2 1 Bulan MEGATRON 5 500,000 750,000 1,000,00 M2 100,000 1 Tahun / 0 /3 Bln VIDIATRON 6 KAIN - 40,000 50,000 50,000 M2 7 Hari SPANDUK 7 POSTER 10,000 12,500 15,000 M2 1 Bulan 8 BERJALAN 7,500...\n",
      "\n",
      "Chunk #3 (filename: Perda Kota Cimahi No. 8 Tahun 2014.pdf, part: 1, index: 109, length: 972):\n",
      "\n",
      "Bagian Ketujuh Pencatatan Perubahan Status Kewarganegaraan Paragraf 1 Pencatatan Perubahan Status Kewarganegaraan di Wilayah Negara Kesatuan Republik Indonesia Pasal 101 (1) Perubahan status kewraganegaraan dari warga negara asing menjadi warga negara Indonesia wajib dilaporkan oleh penduduk yang bersangkutan kepada Instansi Pelaksana di tempat peristiwa perubahan status kewarganegaraan paling lambat 60 (enam puluh) hari sejak berita acara pengucapan sumpah atau pernyataan janji setia oleh pejab...\n",
      "\n",
      "Chunk #4 (filename: Perda Kota Cimahi No. 8 Tahun 2014.pdf, part: 1, index: 138, length: 958):\n",
      "\n",
      "Biodata Penduduk, KK dan KTP-el, Surat Keterangan Pindah Penduduk Warga Negara Republik Indonesia antar Kabupaten/Kota dalam satu Provinsi dan antar Provinsi dalam wilayah Negara Kesatuan Republik Indonesia, Surat Keterangan Pindah Datang Penduduk Warga Negara Indonesia antar Kabupaten/Kota dalam satu Provinsi dan antar Provinsi dalam wilayah Negara Kesatuan Republik Indonesia, Surat Keterangan Pindah Datang Penduduk Orang Asing dalam wilayah Negara Kesatuan Republik Indonesia, Surat Keterangan ...\n",
      "\n",
      "Chunk #5 (filename: Perda Kota Cimahi No. 8 Tahun 2014.pdf, part: 0, index: 88, length: 931):\n",
      "\n",
      "Dalam hal terjadi perubahan elemen data, rusak, atau hilang, Penduduk pemilik KTP-el wajib melaporkan kepada Instansi Pelaksana untuk dilakukan perubahan atau penggantian; (9) Elemen data penduduk tentang agama sebagaimana dimaksud pada ayat (1) bagi Penduduk yang agamanya belum diakui sebagai agama berdasarkan ketentuan Peraturan Perundang-Undangan atau bagi penghayat kepercayaan tidak diisi, tetapi tetap dilayani dan dicatat dalam database kependudukan; (10) Penerbitan KTP-el baru bagi pendudu...\n",
      "\n",
      "Chunk #6 (filename: Perda Kota Cimahi No. 8 Tahun 2014.pdf, part: 1, index: 103, length: 909):\n",
      "\n",
      "Paragraf Keempat Pencatatan Pengesahan Anak Pasal 99 (1) Setiap pengesahan Anak Wajib dilaporkan oleh orangtua kepada Instansi Pelaksana paling lambat 30 (tiga puluh) hari sejak ayah dan ibu dari anak yang bersangkutan melakukan perkawinan dan men- dapatkan Akta perkawinan; (2) Pengesahan Anak hanya berlaku bagi anak yang orangtuanya telah melaksanakan perkawinan yang sah menurut hukum agama dan hukum negara; (3) Pencatatan pelaporan pengesahan anak dilakukan pada Instansi Pelaksana atau UPTD In...\n",
      "\n",
      "Chunk #7 (filename: Perwal Cimahi 6 2024.pdf, part: 0, index: 0, length: 762):\n",
      "\n",
      "- 2 - lndonesia Tahun 2023 Nomor 41, Tambahan Lembaran Negara Republik lndonesia Nomor 6856); 3. Undang-Undang Nomor 1 Tahun 2022 tentang Hubungan Keuangan antara Pemerintah Pusat dan Pemerintahan Daerah (Lembaran Negara Republik Indonesia Tahun 2022 Nomor 4, Tambahan Lembaran Negara Republik Indonesia Nomor 6757); 4. Peraturan Pemerintah Nomor 4 Tahun 2023 tentang Pemungutan Pajak Barang dan Jasa Tertentu atas Tenaga Listrik (Lembaran Negara Republik Indonesia Tahun 2023 Nomor 17, Tambahan Lemb...\n",
      "\n",
      "Chunk #8 (filename: Perwal Cimahi 6 2024.pdf, part: 0, index: 133, length: 660):\n",
      "\n",
      "pembetulan SKPD atau SPPT atau dokumen sejenis lainnya. Bagian Kedua Penetapan PBB-P2 Pasal 51 Penetapan PBB-P2 atas objek Pajak baru ditetapkan 5 (lima) tahun sebelumnya, termasuk Tahun Pajak berjalan atau sejak kepemilikan/penguasaan tanah dan bangunan oleh Wajib Pajak. Pasal 52 (1) Selain penetapan sebagaimana dimaksud dalam Pasal 51, penetapan dapat dilakukan dengan cara penilaian: a. massal untuk objek pajak standar; dan b. individual untuk objek pajak non standar dan objek pajak khusus. (2...\n",
      "\n",
      "Chunk #9 (filename: Perwal Cimahi 6 2024.pdf, part: 1, index: 148, length: 514):\n",
      "\n",
      "PENGHITUNGAN PERSENTASE PENGURANGAN PAJAK BUMI DAN BANGUNAN BAGI WAJIB PAJAK ORANG PRIBADI PENSIUNAN PEGAWAI NEGERI SIPIL/TENTARA NASIONAL INDONESIA/KEPOLISIAN NEGARA REPUBLIK INDONESIA, ATAU PEGAWAI SWASTA, TERMASUK PEGAWAI BADAN USAHA MILIK NEGARA/DAERAH Persentase pengurangan pajak bagi wajib pajak orang pribadi pensiunan Pegawai Negeri Sipil/Tentara Nasional Indonesia/ Kepolisian Negara Republik Indonesia, atau Pegawai Swasta, termasuk pegawai Badan Usaha Milik Negara/Daerah didasarkan pada ...\n",
      "\n",
      "Chunk #10 (filename: Perda No 8 2011 IMB.pdf, part: 1, index: 6, length: 502):\n",
      "\n",
      "Ditetapkan di Bandung Barat pada tanggal 15 April 2011 BUPATI BANDUNG BARAT, ttd. ABUBAKAR Diundangkan di Bandung Barat pada tanggal 15 April 2011 SEKRETARIS DAERAH KABUPATEN BANDUNG BARAT, ttd. MAS ABDUL KOHAR LEMBARAN DAERAH KABUPATEN BANDUNG BARAT TAHUN 2011 NOMOR 8 LAMPIRAN I PERATURAN DAERAH KABUPATEN BANDUNG BARAT NOMOR 8 TAHUN 2011 TENTANG PENYELENGGARAAN PENATAAN BANGUNAN DAN RETRIBUSI IZIN MENDIRIKAN BANGUNAN BESARAN HARGA DASAR BANGUNAN I. HARGA DASAR BANGUNAN GEDUNG A. FUNGSI HUNIAN 1...\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import json\n",
    "\n",
    "def show_chunk_stats(chunk_file, n=5):\n",
    "    \"\"\"Display total chunk count and show n longest chunks by length.\"\"\"\n",
    "    with open(chunk_file, 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "    print(f\"Total chunks: {len(chunks)}\\n\")\n",
    "    # Sort by chunk length (descending)\n",
    "    sorted_chunks = sorted(chunks, key=lambda x: len(x['chunk']), reverse=True)\n",
    "    print(f\"Top {n} longest chunks:\")\n",
    "    for i, chunk in enumerate(sorted_chunks[:n]):\n",
    "        print(f\"\\nChunk #{i+1} (filename: {chunk['filename']}, part: {chunk.get('doc_part', 0)}, index: {chunk['chunk_index']}, length: {len(chunk['chunk'])}):\\n\")\n",
    "        print(chunk['chunk'][:500] + ('...' if len(chunk['chunk']) > 500 else ''))\n",
    "\n",
    "# Example usage\n",
    "show_chunk_stats('TestChunk/chunks.json', n=10\n",
    "                 )\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b96336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f17098",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m         json.dump(embeddings, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m4\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43membed_chunks_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTestChunk/chunks.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTestChunk/embeddings.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://api.jina.ai/v1/embeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mJINA_API_KEY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\n\u001b[32m     52\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36membed_chunks_batch\u001b[39m\u001b[34m(chunk_file, output_file, api_url, api_key, model, batch_size, sleep_time)\u001b[39m\n\u001b[32m     20\u001b[39m texts = [c[\u001b[33m\"\u001b[39m\u001b[33mchunk\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     21\u001b[39m data = {\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mretrieval.passage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlate_chunking\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: texts\n\u001b[32m     26\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     29\u001b[39m     emb_list = response.json().get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\urllib3\\response.py:1063\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1060\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\urllib3\\response.py:1219\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1216\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1219\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1221\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project AI\\smart-chatbot\\env\\Lib\\site-packages\\urllib3\\response.py:1138\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1139\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def embed_chunks_batch(chunk_file, output_file, api_url, api_key, model=\"jina-embeddings-v3\", batch_size=8, sleep_time=0.5):\n",
    "    \"\"\"\n",
    "    Embed all chunks using Jina Embeddings API in batches and save the results to a JSON file.\n",
    "    \"\"\"\n",
    "    with open(chunk_file, 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    embeddings = []\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}'\n",
    "    }\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        texts = [c[\"chunk\"] for c in batch]\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"task\": \"retrieval.passage\",\n",
    "            \"late_chunking\": True,\n",
    "            \"input\": texts\n",
    "        }\n",
    "        response = requests.post(api_url, headers=headers, json=data)\n",
    "        if response.status_code == 200:\n",
    "            emb_list = response.json().get(\"data\", [])\n",
    "            for c, emb in zip(batch, emb_list):\n",
    "                embeddings.append({\n",
    "                    \"filename\": c[\"filename\"],\n",
    "                    \"doc_part\": c.get(\"doc_part\", 0),\n",
    "                    \"chunk_index\": c[\"chunk_index\"],\n",
    "                    \"embedding\": emb.get(\"embedding\", [])\n",
    "                })\n",
    "            print(f\"Embedded batch {i//batch_size+1} ({i+1}-{i+len(batch)}) of {len(chunks)})\")\n",
    "        else:\n",
    "            print(f\"Error embedding batch {i//batch_size+1}: {response.status_code} {response.text}\")\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(embeddings, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "embed_chunks_batch(\n",
    "    chunk_file='TestChunk/chunks.json',\n",
    "    output_file='TestChunk/embeddings.json',\n",
    "    api_url='https://api.jina.ai/v1/embeddings',\n",
    "    api_key=os.getenv('JINA_API_KEY'),\n",
    "    batch_size=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844aaf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Load embeddings from embeddings.json\n",
    "with open('embeddings.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract vectors and (optionally) metadata\n",
    "vectors = [item['embedding'] for item in data]\n",
    "# Optionally, save metadata for later retrieval\n",
    "metadata = [\n",
    "    {\n",
    "        'filename': item.get('filename'),\n",
    "        'doc_part': item.get('doc_part'),\n",
    "        'chunk_index': item.get('chunk_index')\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# Convert to numpy array (float32)\n",
    "vecs_np = np.array(vectors, dtype='float32')\n",
    "\n",
    "# Create FAISS index (L2 similarity)\n",
    "dim = vecs_np.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(vecs_np)\n",
    "\n",
    "# Save index to file\n",
    "faiss.write_index(index, 'faiss_index')\n",
    "\n",
    "# Optionally, save metadata for later use\n",
    "with open('faiss_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"FAISS index created with {index.ntotal} vectors and saved to 'faiss_index'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
